{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c8d806-b1d7-444c-ab8e-6d143b4a8b81",
   "metadata": {},
   "source": [
    "**What is Feature Engineering?**\n",
    " \n",
    "            Feature engineering is the process of creating new features or modifying existing ones to improve the performance of machine learning models. It involves techniques like feature extraction, transformation, encoding, and scaling to make data more useful for predictions.\n",
    "            \n",
    "**Why Do We Need Feature Engineering?**\n",
    "\n",
    "1.**Improves Model Performance** – Good features help models make better predictions.\n",
    " \n",
    "2.**Reduces Overfitting** – Helps eliminate noise and irrelevant data.\n",
    " \n",
    "3.**Handles Missing Data** – Creates meaningful replacements for missing values.\n",
    " \n",
    "4.**Enables Better Interpretability** – Makes features more understandable and useful.\n",
    "\n",
    "5.**Reduces Dimensionality** – Helps remove unnecessary data points, making the model efficient.\n",
    "has context menu\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ade961-ac9b-43e5-8a4d-d37f8aeca9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TransactionDate  DayOfWeek  Hour  IsWeekend\n",
      "0 2025-02-05 14:30:00          2    14          0\n",
      "1 2025-02-06 18:45:00          3    18          0\n"
     ]
    }
   ],
   "source": [
    "#Extract Date and Time features\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Sample dataset\n",
    "df=pd.DataFrame({'TransactionDate':pd.to_datetime(['2025-02-05 14:30:00','2025-02-06 18:45:00'])})\n",
    "\n",
    "#Extract date-related features\n",
    "df['DayOfWeek']=df['TransactionDate'].dt.dayofweek\n",
    "df['Hour']=df['TransactionDate'].dt.hour\n",
    "df['IsWeekend']=df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55f3e44-bd92-4495-8f11-c86e3babb5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  AvgTransactionAmount\n",
      "0     101                 600.0\n",
      "1     102                 300.0\n",
      "2     103                 700.0\n"
     ]
    }
   ],
   "source": [
    "#Aggreagted Features\n",
    "#Find average transaction amount per user:\n",
    "df_transactions =pd.DataFrame({\n",
    "    'UserID':[101,102,101,103,103],\n",
    "    'TransactionAmount':[500,300,700,1000,400]\n",
    "})\n",
    "df_user_avg = df_transactions.groupby('UserID')['TransactionAmount'].mean().reset_index()\n",
    "df_user_avg.rename(columns={'TransactionAmount':'AvgTransactionAmount'},inplace=True)\n",
    "print(df_user_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86fef2e6-96ea-4eb6-b5ed-0c08f883cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductCategory_Clothing  ProductCategory_Electronics  \\\n",
      "0                       0.0                          1.0   \n",
      "1                       1.0                          0.0   \n",
      "2                       1.0                          0.0   \n",
      "3                       0.0                          0.0   \n",
      "\n",
      "   ProductCategory_Grocery  \n",
      "0                      0.0  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df=pd.DataFrame({'ProductCategory':['Electronics','Clothing','Clothing','Grocery']})\n",
    "encoder=OneHotEncoder(sparse_output=False)\n",
    "encoded_features=encoder.fit_transform(df[['ProductCategory']])\n",
    "df_encoded=pd.DataFrame(encoded_features,columns=encoder.get_feature_names_out())\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec295f83-06f5-44f0-859e-0d74a14b3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount\n",
      "0                100              4.615121\n",
      "1                200              5.303305\n",
      "2               5000              8.517393\n",
      "3              10000              9.210440\n",
      "4              20000              9.903538\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df=pd.DataFrame({'TransactionAmount':[100,200,5000,10000,20000]})\n",
    "df['LogTransactionAmount']=np.log1p(df['TransactionAmount'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b006dca-c181-456f-8159-f557bb9931dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount  NormalisedTransactionAmount  \\\n",
      "0                100              4.615121                     0.000000   \n",
      "1                200              5.303305                     0.005025   \n",
      "2               5000              8.517393                     0.246231   \n",
      "3              10000              9.210440                     0.497487   \n",
      "4              20000              9.903538                     1.000000   \n",
      "\n",
      "   StandardizedTransactionAmount  \n",
      "0                      -0.937070  \n",
      "1                      -0.923606  \n",
      "2                      -0.277351  \n",
      "3                       0.395831  \n",
      "4                       1.742196  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler=MinMaxScaler()\n",
    "df['NormalisedTransactionAmount']=scaler.fit_transform(df[['TransactionAmount']])\n",
    "standard_scaler=StandardScaler()\n",
    "df['StandardizedTransactionAmount']=standard_scaler.fit_transform(df[['TransactionAmount']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a68d1-6d44-4a52-beee-990b81a10d93",
   "metadata": {},
   "source": [
    "**Final Summary of Feature Engineering & Imbalanced Data Handling**\n",
    " \n",
    "Feature Extraction : Extract new insights from raw data (e.g., Hour, DayOfWeek)\n",
    " \n",
    "Aggregated Features : Calculate meaningful statistics (e.g., AvgTransactionAmountPerUser)\n",
    " \n",
    "Encoding : Convert categorical variables into numerical (One-Hot Encoding)\n",
    " \n",
    "Log Transformation : Reduce skewness in data distribution\n",
    " \n",
    "Feature Scaling : Normalize numerical features for better model performance\n",
    " \n",
    "Downsampling: Reduce the size of the majority class\n",
    " \n",
    "Upsampling : Increase the size of the minority class\n",
    " \n",
    "SMOTE(Synthetic Minority Over-sampling Technique) : Generate synthetic samples for the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661bf9a-48bd-461e-8f99-5aeba7f90d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
